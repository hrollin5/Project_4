{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "lTs9vvNTr8wD"
      },
      "outputs": [],
      "source": [
        "# Initial imports\n",
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
        "%matplotlib inline\n",
        "import os\n",
        "from scipy.sparse import csr_matrix\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "lFjEYUHVKeds"
      },
      "outputs": [],
      "source": [
        "# Set the limit for max rows and columns to display\n",
        "pd.options.display.max_rows = 50\n",
        "pd.options.display.max_columns = 50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 694
        },
        "id": "panlmJMAr8wI",
        "outputId": "849d4eb5-b099-4f3d-ae9b-74c291d72f17"
      },
      "outputs": [],
      "source": [
        "# Loading data\n",
        "#file_path = \"data\\Traffic_Violations_Processed.csv\"\n",
        "file_path = r\"Traffic_Violations_Processed.csv\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Assuming 'data\\Traffic_Violations_Processed.csv' is the correct path\n",
        "processed_file_path = r\"data\\Traffic_Violations_Processed.csv\"\n",
        "df_traffic = pd.read_csv(processed_file_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current Working Directory: c:\\class_work\\Project_4\n",
            "Files in Current Directory: ['.git', '.gitignore', 'combined_data_cleaning.ipynb', 'data', 'DataExploration_Findings.md', 'data_cleaning.ipynb', 'data_cleaning_binning.ipynb', 'DESCRIPTIONS.docx', 'drop_columns.ipynb', 'dv_data_cleaning.ipynb', 'dv_random_forest copy.ipynb', 'dv_random_forest.ipynb', 'Haley_data_cleaning.ipynb', 'image-1.png', 'image.png', 'README.md', 'Sample_data.csv', 'sm_random_forest.ipynb', 'sm_state_make_cleaning.ipynb', 'tables.ipynb', 'Traffic_Violations.csv']\n"
          ]
        }
      ],
      "source": [
        "print(\"Current Working Directory:\", os.getcwd())\n",
        "print(\"Files in Current Directory:\", os.listdir())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Osxcc4pt9kJ",
        "outputId": "9093aa08-3364-4e8e-cf43-55551bbfe42c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['Date Of Stop', 'Time Of Stop', 'Description', 'Location', 'Latitude',\n",
              "       'Longitude', 'Accident', 'Belts', 'Personal Injury', 'Property Damage',\n",
              "       'Fatal', 'Alcohol', 'Work Zone', 'Search Conducted',\n",
              "       'Search Disposition', 'Search Outcome', 'Search Reason', 'Search Type',\n",
              "       'Search Arrest Reason', 'State', 'Year', 'Make', 'Color',\n",
              "       'Violation Type', 'Race', 'Gender', 'Driver State', 'Year of Stop',\n",
              "       'Month of Stop', 'Driver State Category',\n",
              "       'License Plate State Category', 'Hour of Stop'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_traffic.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "id": "VqdRCMrBtbCh",
        "outputId": "26e00320-5367-4516-94fa-90dd3af2df41"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Race</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Make</th>\n",
              "      <th>Violation Type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>WHITE</td>\n",
              "      <td>F</td>\n",
              "      <td>HYUNDAI</td>\n",
              "      <td>Citation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>BLACK</td>\n",
              "      <td>F</td>\n",
              "      <td>NISSAN</td>\n",
              "      <td>Citation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>BLACK</td>\n",
              "      <td>F</td>\n",
              "      <td>NISSAN</td>\n",
              "      <td>Citation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>BLACK</td>\n",
              "      <td>F</td>\n",
              "      <td>NISSAN</td>\n",
              "      <td>Citation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>BLACK</td>\n",
              "      <td>F</td>\n",
              "      <td>NISSAN</td>\n",
              "      <td>Citation</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Race Gender     Make Violation Type\n",
              "0  WHITE      F  HYUNDAI       Citation\n",
              "1  BLACK      F   NISSAN       Citation\n",
              "2  BLACK      F   NISSAN       Citation\n",
              "3  BLACK      F   NISSAN       Citation\n",
              "4  BLACK      F   NISSAN       Citation"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        " # Get required columns\n",
        "column_list = ['Race','Gender','Make','Violation Type']\n",
        "df_traffic_trimmed = df_traffic[column_list]\n",
        "df_traffic_trimmed.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['Race', 'Gender', 'Make', 'Violation Type'], dtype='object')"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_traffic_trimmed.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FT-MScAnSOEJ",
        "outputId": "feab65a8-44b9-4a16-adf1-d2a42f7512ab"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Warning     909540\n",
              "Citation    756296\n",
              "Name: Violation Type, dtype: int64"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_traffic['Violation Type'].value_counts(dropna=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "uatghuFjUzDk"
      },
      "outputs": [],
      "source": [
        "# Assuming 'Violation Type' is the column with null values\n",
        "df_traffic['Violation Type'] = df_traffic['Violation Type'].fillna(\"None\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fill null values in the entire DataFrame with \"None\"\n",
        "df_traffic_clean = df_traffic.fillna(\"None\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cINo5-8JxEy-",
        "outputId": "984cbd43-aec5-4961-8e3b-387852fa0716"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Date Of Stop                    1665836\n",
              "Time Of Stop                    1665836\n",
              "Description                     1665836\n",
              "Location                        1665836\n",
              "Latitude                        1665836\n",
              "Longitude                       1665836\n",
              "Accident                        1665836\n",
              "Belts                           1665836\n",
              "Personal Injury                 1665836\n",
              "Property Damage                 1665836\n",
              "Fatal                           1665836\n",
              "Alcohol                         1665836\n",
              "Work Zone                       1665836\n",
              "Search Conducted                1665836\n",
              "Search Disposition              1665836\n",
              "Search Outcome                  1665836\n",
              "Search Reason                   1665836\n",
              "Search Type                     1665836\n",
              "Search Arrest Reason            1665836\n",
              "State                           1665836\n",
              "Year                            1665836\n",
              "Make                            1665836\n",
              "Color                           1665836\n",
              "Violation Type                  1665836\n",
              "Race                            1665836\n",
              "Gender                          1665836\n",
              "Driver State                    1665836\n",
              "Year of Stop                    1665836\n",
              "Month of Stop                   1665836\n",
              "Driver State Category           1665836\n",
              "License Plate State Category    1665836\n",
              "Hour of Stop                    1665836\n",
              "dtype: int64"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_traffic_clean.count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "id": "Lign3EqaxVu3",
        "outputId": "54fe79a7-677a-4187-da92-03c2fa30ddaf"
      },
      "outputs": [],
      "source": [
        "# One-hot encoding of categorical columns\n",
        "traffic_dummies = pd.get_dummies(df_traffic_clean[columns_to_encode], columns=columns_to_encode, sparse=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BWhz5brQ0qGD",
        "outputId": "26121256-191d-4261-be1d-8785da8a630d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['Race_ASIAN', 'Race_BLACK', 'Race_HISPANIC', 'Race_NATIVE AMERICAN',\n",
              "       'Race_OTHER', 'Race_WHITE', 'Gender_F', 'Gender_M', 'Gender_U',\n",
              "       'Make_'NISSAN',\n",
              "       ...\n",
              "       'Make_ZUZU', 'Make_ZUZUKI', 'Make_]LEXUS', 'Make_`', 'Make_`DODGE',\n",
              "       'Make_`LINC', 'Make_`SCION', 'Make_`TOYOTA', 'Violation Type_Citation',\n",
              "       'Violation Type_Warning'],\n",
              "      dtype='object', length=3660)"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# # Check the columns after one-hot encoding\n",
        "traffic_dummies.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Update the columns_to_drop list based on the actual column names\n",
        "columns_to_drop = ['Violation Type_Citation', 'Violation Type_Warning']\n",
        "\n",
        "# Drop the specified columns and create a sparse matrix directly\n",
        "X_sparse = csr_matrix(traffic_dummies.drop(columns_to_drop, axis=1).values)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "id": "eqK7wj65xVqR",
        "outputId": "43bcb17e-9b60-4911-ef9d-c0eda106f6c2"
      },
      "outputs": [],
      "source": [
        "# Drop the specified columns directly from the original DataFrame\n",
        "traffic_dummies.drop(['Violation Type_Citation', 'Violation Type_Warning'], axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wZu8nfg6F8NE",
        "outputId": "aad86980-1549-4737-cff5-61edd994f8d3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Warning     909540\n",
              "Citation    756296\n",
              "Name: Violation Type, dtype: int64"
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Check the number of Citation and Warning\n",
        "df_traffic_clean['Violation Type'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Index(['Race_ASIAN', 'Race_BLACK', 'Race_HISPANIC', 'Race_NATIVE AMERICAN',\n",
            "       'Race_OTHER', 'Race_WHITE', 'Gender_F', 'Gender_M', 'Gender_U',\n",
            "       'Make_'NISSAN',\n",
            "       ...\n",
            "       'Make_ZR900', 'Make_ZUMMERQ', 'Make_ZUZU', 'Make_ZUZUKI', 'Make_]LEXUS',\n",
            "       'Make_`', 'Make_`DODGE', 'Make_`LINC', 'Make_`SCION', 'Make_`TOYOTA'],\n",
            "      dtype='object', length=3658)\n"
          ]
        }
      ],
      "source": [
        "print(traffic_dummies.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "audzbxJM3yH_",
        "outputId": "75239a35-dcbd-4f94-d8ed-8d253ac2ad84"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0 0 0 0 0 0 0 0 0 0]\n"
          ]
        }
      ],
      "source": [
        "# Define the outcome column\n",
        "y = (df_traffic_clean['Violation Type'] == 'Warning').astype(int).values\n",
        "\n",
        "# Output 0 represents Citation and 1 represents Warning\n",
        "print(y[:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1 1 1 1 1 1 1 1 1 1]\n"
          ]
        }
      ],
      "source": [
        "# Define the outcome column\n",
        "x = (df_traffic_clean['Violation Type'] == 'Citation').astype(int).values\n",
        "\n",
        "# Output 0 represents Citation and 1 represents Warning\n",
        "print(x[:10])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "I-l5eWZ358eR"
      },
      "outputs": [],
      "source": [
        "# Select relevant columns for the features\n",
        "feature_columns = ['Race', 'Gender', 'Make'] \n",
        "\n",
        "# Create the feature set X and outcome variable y\n",
        "X = df_traffic_clean[feature_columns]\n",
        "y = (df_traffic_clean['Violation Type'] == 'Warning').astype(int)\n",
        "\n",
        "# Splitting into Train and Test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=35)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dKeDl7SR-aYu"
      },
      "source": [
        "## Fitting the Random Forest Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "U1bJi57I9nm3"
      },
      "outputs": [],
      "source": [
        "# Create a random forest classifier\n",
        "rf_model = RandomForestClassifier(n_estimators=200, random_state=35)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {},
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "could not convert string to float: 'HISPANIC'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[1;32mc:\\class_work\\Project_4\\dv_random_forest copy.ipynb Cell 24\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/class_work/Project_4/dv_random_forest%20copy.ipynb#X50sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Train the Random Forest model\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/class_work/Project_4/dv_random_forest%20copy.ipynb#X50sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m rf_model\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n",
            "File \u001b[1;32mc:\\Users\\Owner\\anaconda3\\envs\\dev\\lib\\site-packages\\sklearn\\base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[0;32m   1147\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1150\u001b[0m     )\n\u001b[0;32m   1151\u001b[0m ):\n\u001b[1;32m-> 1152\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\Owner\\anaconda3\\envs\\dev\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:348\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    346\u001b[0m \u001b[39mif\u001b[39;00m issparse(y):\n\u001b[0;32m    347\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39msparse multilabel-indicator for y is not supported.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 348\u001b[0m X, y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[0;32m    349\u001b[0m     X, y, multi_output\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsc\u001b[39;49m\u001b[39m\"\u001b[39;49m, dtype\u001b[39m=\u001b[39;49mDTYPE\n\u001b[0;32m    350\u001b[0m )\n\u001b[0;32m    351\u001b[0m \u001b[39mif\u001b[39;00m sample_weight \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    352\u001b[0m     sample_weight \u001b[39m=\u001b[39m _check_sample_weight(sample_weight, X)\n",
            "File \u001b[1;32mc:\\Users\\Owner\\anaconda3\\envs\\dev\\lib\\site-packages\\sklearn\\base.py:622\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    620\u001b[0m         y \u001b[39m=\u001b[39m check_array(y, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_y_params)\n\u001b[0;32m    621\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 622\u001b[0m         X, y \u001b[39m=\u001b[39m check_X_y(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_params)\n\u001b[0;32m    623\u001b[0m     out \u001b[39m=\u001b[39m X, y\n\u001b[0;32m    625\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m check_params\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mensure_2d\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n",
            "File \u001b[1;32mc:\\Users\\Owner\\anaconda3\\envs\\dev\\lib\\site-packages\\sklearn\\utils\\validation.py:1146\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1141\u001b[0m         estimator_name \u001b[39m=\u001b[39m _check_estimator_name(estimator)\n\u001b[0;32m   1142\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1143\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mestimator_name\u001b[39m}\u001b[39;00m\u001b[39m requires y to be passed, but the target y is None\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1144\u001b[0m     )\n\u001b[1;32m-> 1146\u001b[0m X \u001b[39m=\u001b[39m check_array(\n\u001b[0;32m   1147\u001b[0m     X,\n\u001b[0;32m   1148\u001b[0m     accept_sparse\u001b[39m=\u001b[39;49maccept_sparse,\n\u001b[0;32m   1149\u001b[0m     accept_large_sparse\u001b[39m=\u001b[39;49maccept_large_sparse,\n\u001b[0;32m   1150\u001b[0m     dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[0;32m   1151\u001b[0m     order\u001b[39m=\u001b[39;49morder,\n\u001b[0;32m   1152\u001b[0m     copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[0;32m   1153\u001b[0m     force_all_finite\u001b[39m=\u001b[39;49mforce_all_finite,\n\u001b[0;32m   1154\u001b[0m     ensure_2d\u001b[39m=\u001b[39;49mensure_2d,\n\u001b[0;32m   1155\u001b[0m     allow_nd\u001b[39m=\u001b[39;49mallow_nd,\n\u001b[0;32m   1156\u001b[0m     ensure_min_samples\u001b[39m=\u001b[39;49mensure_min_samples,\n\u001b[0;32m   1157\u001b[0m     ensure_min_features\u001b[39m=\u001b[39;49mensure_min_features,\n\u001b[0;32m   1158\u001b[0m     estimator\u001b[39m=\u001b[39;49mestimator,\n\u001b[0;32m   1159\u001b[0m     input_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mX\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m   1160\u001b[0m )\n\u001b[0;32m   1162\u001b[0m y \u001b[39m=\u001b[39m _check_y(y, multi_output\u001b[39m=\u001b[39mmulti_output, y_numeric\u001b[39m=\u001b[39my_numeric, estimator\u001b[39m=\u001b[39mestimator)\n\u001b[0;32m   1164\u001b[0m check_consistent_length(X, y)\n",
            "File \u001b[1;32mc:\\Users\\Owner\\anaconda3\\envs\\dev\\lib\\site-packages\\sklearn\\utils\\validation.py:915\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    913\u001b[0m         array \u001b[39m=\u001b[39m xp\u001b[39m.\u001b[39mastype(array, dtype, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m    914\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 915\u001b[0m         array \u001b[39m=\u001b[39m _asarray_with_order(array, order\u001b[39m=\u001b[39;49morder, dtype\u001b[39m=\u001b[39;49mdtype, xp\u001b[39m=\u001b[39;49mxp)\n\u001b[0;32m    916\u001b[0m \u001b[39mexcept\u001b[39;00m ComplexWarning \u001b[39mas\u001b[39;00m complex_warning:\n\u001b[0;32m    917\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    918\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mComplex data not supported\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(array)\n\u001b[0;32m    919\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39mcomplex_warning\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\Owner\\anaconda3\\envs\\dev\\lib\\site-packages\\sklearn\\utils\\_array_api.py:380\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[1;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[0;32m    378\u001b[0m     array \u001b[39m=\u001b[39m numpy\u001b[39m.\u001b[39marray(array, order\u001b[39m=\u001b[39morder, dtype\u001b[39m=\u001b[39mdtype)\n\u001b[0;32m    379\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 380\u001b[0m     array \u001b[39m=\u001b[39m numpy\u001b[39m.\u001b[39;49masarray(array, order\u001b[39m=\u001b[39;49morder, dtype\u001b[39m=\u001b[39;49mdtype)\n\u001b[0;32m    382\u001b[0m \u001b[39m# At this point array is a NumPy ndarray. We convert it to an array\u001b[39;00m\n\u001b[0;32m    383\u001b[0m \u001b[39m# container that is consistent with the input's namespace.\u001b[39;00m\n\u001b[0;32m    384\u001b[0m \u001b[39mreturn\u001b[39;00m xp\u001b[39m.\u001b[39masarray(array)\n",
            "File \u001b[1;32mc:\\Users\\Owner\\anaconda3\\envs\\dev\\lib\\site-packages\\pandas\\core\\generic.py:2070\u001b[0m, in \u001b[0;36mNDFrame.__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m   2069\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__array__\u001b[39m(\u001b[39mself\u001b[39m, dtype: npt\u001b[39m.\u001b[39mDTypeLike \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m np\u001b[39m.\u001b[39mndarray:\n\u001b[1;32m-> 2070\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39;49masarray(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_values, dtype\u001b[39m=\u001b[39;49mdtype)\n",
            "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'HISPANIC'"
          ]
        }
      ],
      "source": [
        "# Train the Random Forest model\n",
        "rf_model.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "B9n42Zx6-uEi"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "could not convert string to float: 'HISPANIC'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[1;32mc:\\class_work\\Project_4\\dv_random_forest copy.ipynb Cell 25\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/class_work/Project_4/dv_random_forest%20copy.ipynb#X23sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Fitting the model\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/class_work/Project_4/dv_random_forest%20copy.ipynb#X23sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m rf_model \u001b[39m=\u001b[39m rf_model\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n",
            "File \u001b[1;32mc:\\Users\\Owner\\anaconda3\\envs\\dev\\lib\\site-packages\\sklearn\\base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[0;32m   1147\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1150\u001b[0m     )\n\u001b[0;32m   1151\u001b[0m ):\n\u001b[1;32m-> 1152\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\Owner\\anaconda3\\envs\\dev\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:348\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    346\u001b[0m \u001b[39mif\u001b[39;00m issparse(y):\n\u001b[0;32m    347\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39msparse multilabel-indicator for y is not supported.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 348\u001b[0m X, y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[0;32m    349\u001b[0m     X, y, multi_output\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsc\u001b[39;49m\u001b[39m\"\u001b[39;49m, dtype\u001b[39m=\u001b[39;49mDTYPE\n\u001b[0;32m    350\u001b[0m )\n\u001b[0;32m    351\u001b[0m \u001b[39mif\u001b[39;00m sample_weight \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    352\u001b[0m     sample_weight \u001b[39m=\u001b[39m _check_sample_weight(sample_weight, X)\n",
            "File \u001b[1;32mc:\\Users\\Owner\\anaconda3\\envs\\dev\\lib\\site-packages\\sklearn\\base.py:622\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    620\u001b[0m         y \u001b[39m=\u001b[39m check_array(y, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_y_params)\n\u001b[0;32m    621\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 622\u001b[0m         X, y \u001b[39m=\u001b[39m check_X_y(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_params)\n\u001b[0;32m    623\u001b[0m     out \u001b[39m=\u001b[39m X, y\n\u001b[0;32m    625\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m check_params\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mensure_2d\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n",
            "File \u001b[1;32mc:\\Users\\Owner\\anaconda3\\envs\\dev\\lib\\site-packages\\sklearn\\utils\\validation.py:1146\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1141\u001b[0m         estimator_name \u001b[39m=\u001b[39m _check_estimator_name(estimator)\n\u001b[0;32m   1142\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1143\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mestimator_name\u001b[39m}\u001b[39;00m\u001b[39m requires y to be passed, but the target y is None\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1144\u001b[0m     )\n\u001b[1;32m-> 1146\u001b[0m X \u001b[39m=\u001b[39m check_array(\n\u001b[0;32m   1147\u001b[0m     X,\n\u001b[0;32m   1148\u001b[0m     accept_sparse\u001b[39m=\u001b[39;49maccept_sparse,\n\u001b[0;32m   1149\u001b[0m     accept_large_sparse\u001b[39m=\u001b[39;49maccept_large_sparse,\n\u001b[0;32m   1150\u001b[0m     dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[0;32m   1151\u001b[0m     order\u001b[39m=\u001b[39;49morder,\n\u001b[0;32m   1152\u001b[0m     copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[0;32m   1153\u001b[0m     force_all_finite\u001b[39m=\u001b[39;49mforce_all_finite,\n\u001b[0;32m   1154\u001b[0m     ensure_2d\u001b[39m=\u001b[39;49mensure_2d,\n\u001b[0;32m   1155\u001b[0m     allow_nd\u001b[39m=\u001b[39;49mallow_nd,\n\u001b[0;32m   1156\u001b[0m     ensure_min_samples\u001b[39m=\u001b[39;49mensure_min_samples,\n\u001b[0;32m   1157\u001b[0m     ensure_min_features\u001b[39m=\u001b[39;49mensure_min_features,\n\u001b[0;32m   1158\u001b[0m     estimator\u001b[39m=\u001b[39;49mestimator,\n\u001b[0;32m   1159\u001b[0m     input_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mX\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m   1160\u001b[0m )\n\u001b[0;32m   1162\u001b[0m y \u001b[39m=\u001b[39m _check_y(y, multi_output\u001b[39m=\u001b[39mmulti_output, y_numeric\u001b[39m=\u001b[39my_numeric, estimator\u001b[39m=\u001b[39mestimator)\n\u001b[0;32m   1164\u001b[0m check_consistent_length(X, y)\n",
            "File \u001b[1;32mc:\\Users\\Owner\\anaconda3\\envs\\dev\\lib\\site-packages\\sklearn\\utils\\validation.py:915\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    913\u001b[0m         array \u001b[39m=\u001b[39m xp\u001b[39m.\u001b[39mastype(array, dtype, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m    914\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 915\u001b[0m         array \u001b[39m=\u001b[39m _asarray_with_order(array, order\u001b[39m=\u001b[39;49morder, dtype\u001b[39m=\u001b[39;49mdtype, xp\u001b[39m=\u001b[39;49mxp)\n\u001b[0;32m    916\u001b[0m \u001b[39mexcept\u001b[39;00m ComplexWarning \u001b[39mas\u001b[39;00m complex_warning:\n\u001b[0;32m    917\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    918\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mComplex data not supported\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(array)\n\u001b[0;32m    919\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39mcomplex_warning\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\Owner\\anaconda3\\envs\\dev\\lib\\site-packages\\sklearn\\utils\\_array_api.py:380\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[1;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[0;32m    378\u001b[0m     array \u001b[39m=\u001b[39m numpy\u001b[39m.\u001b[39marray(array, order\u001b[39m=\u001b[39morder, dtype\u001b[39m=\u001b[39mdtype)\n\u001b[0;32m    379\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 380\u001b[0m     array \u001b[39m=\u001b[39m numpy\u001b[39m.\u001b[39;49masarray(array, order\u001b[39m=\u001b[39;49morder, dtype\u001b[39m=\u001b[39;49mdtype)\n\u001b[0;32m    382\u001b[0m \u001b[39m# At this point array is a NumPy ndarray. We convert it to an array\u001b[39;00m\n\u001b[0;32m    383\u001b[0m \u001b[39m# container that is consistent with the input's namespace.\u001b[39;00m\n\u001b[0;32m    384\u001b[0m \u001b[39mreturn\u001b[39;00m xp\u001b[39m.\u001b[39masarray(array)\n",
            "File \u001b[1;32mc:\\Users\\Owner\\anaconda3\\envs\\dev\\lib\\site-packages\\pandas\\core\\generic.py:2070\u001b[0m, in \u001b[0;36mNDFrame.__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m   2069\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__array__\u001b[39m(\u001b[39mself\u001b[39m, dtype: npt\u001b[39m.\u001b[39mDTypeLike \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m np\u001b[39m.\u001b[39mndarray:\n\u001b[1;32m-> 2070\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39;49masarray(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_values, dtype\u001b[39m=\u001b[39;49mdtype)\n",
            "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'HISPANIC'"
          ]
        }
      ],
      "source": [
        "# Fitting the model\n",
        "rf_model = rf_model.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6LSHr2V7_Fis"
      },
      "source": [
        "## Making Predictions using the Random Forest Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "7ik1jmhZ_BLf"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "could not convert string to float: 'BLACK'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[1;32mc:\\class_work\\Project_4\\dv_random_forest copy.ipynb Cell 27\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/class_work/Project_4/dv_random_forest%20copy.ipynb#X25sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Making predictions using the testing data\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/class_work/Project_4/dv_random_forest%20copy.ipynb#X25sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m predictions \u001b[39m=\u001b[39m rf_model\u001b[39m.\u001b[39;49mpredict(X_test)\n",
            "File \u001b[1;32mc:\\Users\\Owner\\anaconda3\\envs\\dev\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:823\u001b[0m, in \u001b[0;36mForestClassifier.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    802\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[0;32m    803\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    804\u001b[0m \u001b[39m    Predict class for X.\u001b[39;00m\n\u001b[0;32m    805\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    821\u001b[0m \u001b[39m        The predicted classes.\u001b[39;00m\n\u001b[0;32m    822\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 823\u001b[0m     proba \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpredict_proba(X)\n\u001b[0;32m    825\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_outputs_ \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    826\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_\u001b[39m.\u001b[39mtake(np\u001b[39m.\u001b[39margmax(proba, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m), axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
            "File \u001b[1;32mc:\\Users\\Owner\\anaconda3\\envs\\dev\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:865\u001b[0m, in \u001b[0;36mForestClassifier.predict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    863\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[0;32m    864\u001b[0m \u001b[39m# Check data\u001b[39;00m\n\u001b[1;32m--> 865\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_X_predict(X)\n\u001b[0;32m    867\u001b[0m \u001b[39m# Assign chunk of trees to jobs\u001b[39;00m\n\u001b[0;32m    868\u001b[0m n_jobs, _, _ \u001b[39m=\u001b[39m _partition_estimators(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_estimators, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_jobs)\n",
            "File \u001b[1;32mc:\\Users\\Owner\\anaconda3\\envs\\dev\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:599\u001b[0m, in \u001b[0;36mBaseForest._validate_X_predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    596\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    597\u001b[0m \u001b[39mValidate X whenever one tries to predict, apply, predict_proba.\"\"\"\u001b[39;00m\n\u001b[0;32m    598\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[1;32m--> 599\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(X, dtype\u001b[39m=\u001b[39;49mDTYPE, accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m, reset\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m    600\u001b[0m \u001b[39mif\u001b[39;00m issparse(X) \u001b[39mand\u001b[39;00m (X\u001b[39m.\u001b[39mindices\u001b[39m.\u001b[39mdtype \u001b[39m!=\u001b[39m np\u001b[39m.\u001b[39mintc \u001b[39mor\u001b[39;00m X\u001b[39m.\u001b[39mindptr\u001b[39m.\u001b[39mdtype \u001b[39m!=\u001b[39m np\u001b[39m.\u001b[39mintc):\n\u001b[0;32m    601\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mNo support for np.int64 index based sparse matrices\u001b[39m\u001b[39m\"\u001b[39m)\n",
            "File \u001b[1;32mc:\\Users\\Owner\\anaconda3\\envs\\dev\\lib\\site-packages\\sklearn\\base.py:605\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    603\u001b[0m         out \u001b[39m=\u001b[39m X, y\n\u001b[0;32m    604\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> 605\u001b[0m     out \u001b[39m=\u001b[39m check_array(X, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mX\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_params)\n\u001b[0;32m    606\u001b[0m \u001b[39melif\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_y:\n\u001b[0;32m    607\u001b[0m     out \u001b[39m=\u001b[39m _check_y(y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_params)\n",
            "File \u001b[1;32mc:\\Users\\Owner\\anaconda3\\envs\\dev\\lib\\site-packages\\sklearn\\utils\\validation.py:915\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    913\u001b[0m         array \u001b[39m=\u001b[39m xp\u001b[39m.\u001b[39mastype(array, dtype, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m    914\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 915\u001b[0m         array \u001b[39m=\u001b[39m _asarray_with_order(array, order\u001b[39m=\u001b[39;49morder, dtype\u001b[39m=\u001b[39;49mdtype, xp\u001b[39m=\u001b[39;49mxp)\n\u001b[0;32m    916\u001b[0m \u001b[39mexcept\u001b[39;00m ComplexWarning \u001b[39mas\u001b[39;00m complex_warning:\n\u001b[0;32m    917\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    918\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mComplex data not supported\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(array)\n\u001b[0;32m    919\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39mcomplex_warning\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\Owner\\anaconda3\\envs\\dev\\lib\\site-packages\\sklearn\\utils\\_array_api.py:380\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[1;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[0;32m    378\u001b[0m     array \u001b[39m=\u001b[39m numpy\u001b[39m.\u001b[39marray(array, order\u001b[39m=\u001b[39morder, dtype\u001b[39m=\u001b[39mdtype)\n\u001b[0;32m    379\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 380\u001b[0m     array \u001b[39m=\u001b[39m numpy\u001b[39m.\u001b[39;49masarray(array, order\u001b[39m=\u001b[39;49morder, dtype\u001b[39m=\u001b[39;49mdtype)\n\u001b[0;32m    382\u001b[0m \u001b[39m# At this point array is a NumPy ndarray. We convert it to an array\u001b[39;00m\n\u001b[0;32m    383\u001b[0m \u001b[39m# container that is consistent with the input's namespace.\u001b[39;00m\n\u001b[0;32m    384\u001b[0m \u001b[39mreturn\u001b[39;00m xp\u001b[39m.\u001b[39masarray(array)\n",
            "File \u001b[1;32mc:\\Users\\Owner\\anaconda3\\envs\\dev\\lib\\site-packages\\pandas\\core\\generic.py:2070\u001b[0m, in \u001b[0;36mNDFrame.__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m   2069\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__array__\u001b[39m(\u001b[39mself\u001b[39m, dtype: npt\u001b[39m.\u001b[39mDTypeLike \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m np\u001b[39m.\u001b[39mndarray:\n\u001b[1;32m-> 2070\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39;49masarray(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_values, dtype\u001b[39m=\u001b[39;49mdtype)\n",
            "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'BLACK'"
          ]
        }
      ],
      "source": [
        "# Making predictions using the testing data\n",
        "predictions = rf_model.predict(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6hGkWUGA_hCV"
      },
      "source": [
        "## Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "Zkp4RHWh_kVi"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'predictions' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32mc:\\class_work\\Project_4\\dv_random_forest copy.ipynb Cell 29\u001b[0m line \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/class_work/Project_4/dv_random_forest%20copy.ipynb#X30sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Calculating the confusion matrix \u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/class_work/Project_4/dv_random_forest%20copy.ipynb#X30sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m#index=[\"Actual 0\", \"Actual 1\"], columns=[\"Predicted 0\", \"Predicted 1\"]\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/class_work/Project_4/dv_random_forest%20copy.ipynb#X30sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m cm \u001b[39m=\u001b[39m confusion_matrix(y_test, predictions)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/class_work/Project_4/dv_random_forest%20copy.ipynb#X30sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m cm_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/class_work/Project_4/dv_random_forest%20copy.ipynb#X30sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     cm, index\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mActual Citation\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mActual Warning\u001b[39m\u001b[39m\"\u001b[39m], columns\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mPredicted Citation\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mPredicted Warning\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/class_work/Project_4/dv_random_forest%20copy.ipynb#X30sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m )\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/class_work/Project_4/dv_random_forest%20copy.ipynb#X30sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39m# Calculating the accuracy score\u001b[39;00m\n",
            "\u001b[1;31mNameError\u001b[0m: name 'predictions' is not defined"
          ]
        }
      ],
      "source": [
        "# Calculating the confusion matrix \n",
        "#index=[\"Actual 0\", \"Actual 1\"], columns=[\"Predicted 0\", \"Predicted 1\"]\n",
        "\n",
        "cm = confusion_matrix(y_test, predictions)\n",
        "cm_df = pd.DataFrame(\n",
        "    cm, index=[\"Actual Citation\", \"Actual Warning\"], columns=[\"Predicted Citation\", \"Predicted Warning\"]\n",
        ")\n",
        "\n",
        "# Calculating the accuracy score\n",
        "acc_score = accuracy_score(y_test, predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "id": "EI5okEmnAVmi",
        "outputId": "1a867ca4-437f-416e-b3b2-5683402f7b12"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Confusion Matrix:\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'cm_df' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32mc:\\class_work\\Project_4\\dv_random_forest copy.ipynb Cell 30\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/class_work/Project_4/dv_random_forest%20copy.ipynb#X31sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Displaying results\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/class_work/Project_4/dv_random_forest%20copy.ipynb#X31sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mConfusion Matrix:\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/class_work/Project_4/dv_random_forest%20copy.ipynb#X31sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m display(cm_df)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/class_work/Project_4/dv_random_forest%20copy.ipynb#X31sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mAccuracy Score : \u001b[39m\u001b[39m{\u001b[39;00macc_score\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/class_work/Project_4/dv_random_forest%20copy.ipynb#X31sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mClassification Report:\u001b[39m\u001b[39m\"\u001b[39m)\n",
            "\u001b[1;31mNameError\u001b[0m: name 'cm_df' is not defined"
          ]
        }
      ],
      "source": [
        "# Displaying results\n",
        "print(\"Confusion Matrix:\")\n",
        "display(cm_df)\n",
        "print(f\"Accuracy Score : {acc_score}\")\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, predictions))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
